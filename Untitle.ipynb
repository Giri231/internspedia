{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562e59f4",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee568384",
   "metadata": {},
   "source": [
    "A handwritten digit recognizer using MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de0abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The used packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d70ee",
   "metadata": {},
   "source": [
    "<h2>Loading the data</h2>\n",
    "\n",
    "I have divided the data into three groups:<br>\n",
    "training data (xtr,ytr) : used to train the model<br>\n",
    "validation data (xval,yval) : used to tone the model<br>\n",
    "test data (xtest,ytest) : used for the final evaluation of the model<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708fe524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "Type of data is  <class 'numpy.ndarray'> <class 'numpy.uint8'>\n",
      "255 9 255 9\n",
      "(2000, 28, 28) (2000,) (8000, 28, 28) (8000,)\n"
     ]
    }
   ],
   "source": [
    "(xtr,ytr),(x,y) = keras.datasets.mnist.load_data()\n",
    "print(xtr.shape, ytr.shape)\n",
    "print(x.shape,y.shape)\n",
    "print('Type of data is ',type(xtr[0]),type(ytr[0]))\n",
    "print(xtr.max(),ytr.max(),x.max(),y.max())\n",
    "#dividing x and y into valdition and test data\n",
    "xval,xtest,yval,ytest=x[0:8000],x[8000:10000],y[0:8000],y[8000:10000]\n",
    "print(xtest.shape,ytest.shape,xval.shape,yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0bf30",
   "metadata": {},
   "source": [
    "<h2> Visualizing the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca745fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'The first ten numbers of the training set')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show the first ten numbers\n",
    "#(1,10)= 1 rows, ten columns\n",
    "#x = an array of Axes objects\n",
    "figure,x = plt.subplots(1,10)\n",
    "for i in range(10):\n",
    "    x[i].imshow(xtr[i])\n",
    "    x[i].set_title(ytr[i])\n",
    "    #don't show axis, cuz it's ugly here :(\n",
    "    x[i].axis('off')\n",
    "figure.suptitle(\"The first ten numbers of the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab3529",
   "metadata": {},
   "source": [
    "<h2>Pre-Processing</h2>\n",
    "\n",
    "since the data is already known to be clean, the Pre-Processing stage will be a short and nice one: I have only normalized the data, and done one hot encoding on the labels. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035abb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First digit: [7]\n",
      "One-hot-encoded version:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the data\n",
    "#using float 16 insted of float 32 since it's more efficient\n",
    "xtr = xtr.astype(np.float16)/255.0\n",
    "xval = xval.astype(np.float16)/255.0\n",
    "xtest = xtest.astype(np.float16)/255.0\n",
    "\n",
    "#one hot encoding \n",
    "ytr_oh = keras.utils.to_categorical(ytr)\n",
    "yval_oh = keras.utils.to_categorical(yval)\n",
    "ytest_oh = keras.utils.to_categorical(ytest)\n",
    "\n",
    "print(\"First digit:\",yval[:1])\n",
    "print(\"One-hot-encoded version:\\n\",yval_oh[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c2e4b",
   "metadata": {},
   "source": [
    "<h2>Modeling, Toning  and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa3055",
   "metadata": {},
   "source": [
    "I started with a small general model and then added more complexity until I started having an overfitting problem, then I moved on to a convolutional neural network. I have built 4 models and the last one was the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74772890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3770 - acc: 0.8921 - val_loss: 0.3335 - val_acc: 0.9044\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3033 - acc: 0.9145 - val_loss: 0.3127 - val_acc: 0.9112\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2896 - acc: 0.9182 - val_loss: 0.2989 - val_acc: 0.9158\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2825 - acc: 0.9207 - val_loss: 0.3045 - val_acc: 0.9160\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2773 - acc: 0.9224 - val_loss: 0.3071 - val_acc: 0.9149\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2744 - acc: 0.9237 - val_loss: 0.2955 - val_acc: 0.9168\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2706 - acc: 0.9246 - val_loss: 0.3089 - val_acc: 0.9162\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2693 - acc: 0.9247 - val_loss: 0.3004 - val_acc: 0.9174\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2676 - acc: 0.9262 - val_loss: 0.2938 - val_acc: 0.9180\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2651 - acc: 0.9261 - val_loss: 0.2984 - val_acc: 0.9156\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2640 - acc: 0.9261 - val_loss: 0.2952 - val_acc: 0.9178\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2623 - acc: 0.9271 - val_loss: 0.3090 - val_acc: 0.9160\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2614 - acc: 0.9273 - val_loss: 0.2901 - val_acc: 0.9193\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2603 - acc: 0.9277 - val_loss: 0.2969 - val_acc: 0.9195\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2583 - acc: 0.9279 - val_loss: 0.2985 - val_acc: 0.9187\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2581 - acc: 0.9285 - val_loss: 0.2913 - val_acc: 0.9210\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2577 - acc: 0.9282 - val_loss: 0.3012 - val_acc: 0.9174\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2564 - acc: 0.9290 - val_loss: 0.2935 - val_acc: 0.9196\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2552 - acc: 0.9293 - val_loss: 0.2963 - val_acc: 0.9175\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2553 - acc: 0.9289 - val_loss: 0.2929 - val_acc: 0.9185\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2543 - acc: 0.9297 - val_loss: 0.2954 - val_acc: 0.9208\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2539 - acc: 0.9291 - val_loss: 0.2990 - val_acc: 0.9166\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2533 - acc: 0.9296 - val_loss: 0.3082 - val_acc: 0.9165\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2530 - acc: 0.9297 - val_loss: 0.3030 - val_acc: 0.9189\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2524 - acc: 0.9300 - val_loss: 0.2960 - val_acc: 0.9210\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model1 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model1.add(Flatten(input_shape=(28,28)))\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model1.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model1.compile(SGD(momentum=0.5,learning_rate=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model1.fit(xtr,ytr_oh,validation_data=(xval,yval_oh), epochs=25)\n",
    "model1.summary()\n",
    "#that model's val_accuracy is already 92.2% although it's very simple one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afdeed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1873 - acc: 0.9425\n",
      "Accuracy: 94.25\n"
     ]
    }
   ],
   "source": [
    "#final evalution of model1\n",
    "_, accuracy = model1.evaluate(xtest,ytest_oh)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73467f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3062 - acc: 0.9111 - val_loss: 0.1916 - val_acc: 0.9423\n",
      "Epoch 2/21\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1482 - acc: 0.9576 - val_loss: 0.1467 - val_acc: 0.9555\n",
      "Epoch 3/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1076 - acc: 0.9685 - val_loss: 0.1111 - val_acc: 0.9650\n",
      "Epoch 4/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0857 - acc: 0.9751 - val_loss: 0.1007 - val_acc: 0.9688\n",
      "Epoch 5/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0709 - acc: 0.9792 - val_loss: 0.0988 - val_acc: 0.9695\n",
      "Epoch 6/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0606 - acc: 0.9823 - val_loss: 0.0886 - val_acc: 0.9743\n",
      "Epoch 7/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0520 - acc: 0.9849 - val_loss: 0.0836 - val_acc: 0.9743\n",
      "Epoch 8/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0461 - acc: 0.9866 - val_loss: 0.0809 - val_acc: 0.9759\n",
      "Epoch 9/21\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.0783 - val_acc: 0.9751\n",
      "Epoch 10/21\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0351 - acc: 0.9901 - val_loss: 0.0800 - val_acc: 0.9756\n",
      "Epoch 11/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0307 - acc: 0.9922 - val_loss: 0.0828 - val_acc: 0.9737\n",
      "Epoch 12/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0265 - acc: 0.9934 - val_loss: 0.0800 - val_acc: 0.9754\n",
      "Epoch 13/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0238 - acc: 0.9941 - val_loss: 0.0812 - val_acc: 0.9750\n",
      "Epoch 14/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0211 - acc: 0.9952 - val_loss: 0.0780 - val_acc: 0.9761\n",
      "Epoch 15/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0185 - acc: 0.9957 - val_loss: 0.0753 - val_acc: 0.9779\n",
      "Epoch 16/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0163 - acc: 0.9967 - val_loss: 0.0744 - val_acc: 0.9761\n",
      "Epoch 17/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0145 - acc: 0.9975 - val_loss: 0.0736 - val_acc: 0.9756\n",
      "Epoch 18/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0130 - acc: 0.9977 - val_loss: 0.0748 - val_acc: 0.9780\n",
      "Epoch 19/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0113 - acc: 0.9983 - val_loss: 0.0784 - val_acc: 0.9775\n",
      "Epoch 20/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0101 - acc: 0.9987 - val_loss: 0.0744 - val_acc: 0.9774\n",
      "Epoch 21/21\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0749 - val_acc: 0.9784\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Multi-Layer networks\n",
    "#adding more hidden layers\n",
    "#starting with a simple model of only 2 layers\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model2 = Sequential()\n",
    "#the dimension of our digit images is 28×28.Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called Flatten, to change tensor shape from 28×28 to 784\n",
    "model2.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# 784 inputs, 100 outputs\n",
    "model2.add(Dense(100,activation=\"relu\"))     \n",
    "\n",
    "#We want th output of the network to return the probability of the input digit being equal to  . Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability. To turn it into a probability we need to apply another layer called Softmax.\n",
    "model2.add(Dense(10,activation=\"softmax\"))\n",
    "           \n",
    "model2.compile(SGD(learning_rate=.1),loss='categorical_crossentropy',metrics=['acc'])\n",
    "model2.fit(xtr,ytr_oh,validation_data=(xval,yval_oh), epochs=21)\n",
    "model2.summary()\n",
    "#val_accuracy = %97.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed26af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0466 - acc: 0.9865\n",
      "Accuracy: 98.65\n"
     ]
    }
   ],
   "source": [
    "#final evalution of model2\n",
    "_, accuracy = model2.evaluate(xtest,ytest_oh)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bec596",
   "metadata": {},
   "source": [
    "<h3>Moving on to CNN:</h3>\n",
    "\n",
    "the layer Conv2D from keras expects the input to be of the shape  W×H×C, where W and H are width and height of the image, and C is the number of color channels. Since the MINST dataset is grayscale, Then we need the same shape with C set to 1 this time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbb31d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "xtr_c = np.expand_dims(xtr,3)\n",
    "xval_c = np.expand_dims(xval,3)\n",
    "xtest_c = np.expand_dims(xtest,3)\n",
    "print(xtr_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff87f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2180 - acc: 0.9364 - val_loss: 0.1047 - val_acc: 0.9693\n",
      "Epoch 2/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0862 - acc: 0.9755 - val_loss: 0.0774 - val_acc: 0.9761\n",
      "Epoch 3/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0666 - acc: 0.9810 - val_loss: 0.0642 - val_acc: 0.9795\n",
      "Epoch 4/21\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0579 - acc: 0.9833 - val_loss: 0.0720 - val_acc: 0.9769\n",
      "Epoch 5/21\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0529 - acc: 0.9851 - val_loss: 0.0626 - val_acc: 0.9789\n",
      "Epoch 6/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0489 - acc: 0.9862 - val_loss: 0.0585 - val_acc: 0.9808\n",
      "Epoch 7/21\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0460 - acc: 0.9868 - val_loss: 0.0607 - val_acc: 0.9814\n",
      "Epoch 8/21\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0445 - acc: 0.9872 - val_loss: 0.0567 - val_acc: 0.9816\n",
      "Epoch 9/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0424 - acc: 0.9879 - val_loss: 0.0604 - val_acc: 0.9811\n",
      "Epoch 10/21\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.0572 - val_acc: 0.9821\n",
      "Epoch 11/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0393 - acc: 0.9887 - val_loss: 0.0594 - val_acc: 0.9819\n",
      "Epoch 12/21\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0377 - acc: 0.9893 - val_loss: 0.0620 - val_acc: 0.9795\n",
      "Epoch 13/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0367 - acc: 0.9897 - val_loss: 0.0572 - val_acc: 0.9819\n",
      "Epoch 14/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0359 - acc: 0.9900 - val_loss: 0.0617 - val_acc: 0.9812\n",
      "Epoch 15/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0344 - acc: 0.9904 - val_loss: 0.0613 - val_acc: 0.9806\n",
      "Epoch 16/21\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0337 - acc: 0.9903 - val_loss: 0.0588 - val_acc: 0.9827\n",
      "Epoch 17/21\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0324 - acc: 0.9910 - val_loss: 0.0627 - val_acc: 0.9831\n",
      "Epoch 18/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0321 - acc: 0.9912 - val_loss: 0.0574 - val_acc: 0.9829\n",
      "Epoch 19/21\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0313 - acc: 0.9911 - val_loss: 0.0668 - val_acc: 0.9808\n",
      "Epoch 20/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0304 - acc: 0.9915 - val_loss: 0.0641 - val_acc: 0.9833\n",
      "Epoch 21/21\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0302 - acc: 0.9918 - val_loss: 0.0604 - val_acc: 0.9839\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 9)         234       \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                51850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,084\n",
      "Trainable params: 52,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model3 = keras.models.Sequential()\n",
    "\n",
    "model3.add(Conv2D(filters=9, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model3.fit(xtr_c,ytr_oh,validation_data=(xval_c,yval_oh),epochs=21)\n",
    "\n",
    "model3.summary()\n",
    "#val_accuracy = %98.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f47d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0420 - acc: 0.9885\n",
      "Accuracy: 98.85\n"
     ]
    }
   ],
   "source": [
    "#final evalution of model3\n",
    "_, accuracy = model3.evaluate(xtest_c,ytest_oh)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54218473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2177 - acc: 0.9321 - val_loss: 0.0840 - val_acc: 0.9715\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0607 - acc: 0.9817 - val_loss: 0.0566 - val_acc: 0.9809\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0406 - acc: 0.9870 - val_loss: 0.0378 - val_acc: 0.9879\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0481 - val_acc: 0.9847\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0275 - acc: 0.9920 - val_loss: 0.0354 - val_acc: 0.9891\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0328 - val_acc: 0.9911\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0195 - acc: 0.9945 - val_loss: 0.0426 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0337 - val_acc: 0.9906\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0342 - val_acc: 0.9918\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 20)          10020     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 20)          10020     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 20)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                810       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,370\n",
      "Trainable params: 21,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model4 = keras.models.Sequential()\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), input_shape=(28,28,1),activation='relu'))\n",
    "model4.add(MaxPooling2D())\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), activation='relu'))\n",
    "\n",
    "model4.add(Conv2D(filters=20, kernel_size=(5,5), activation='relu'))\n",
    "model4.add(MaxPooling2D())\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model4.fit(xtr_c,ytr_oh,validation_data=(xval_c,yval_oh),epochs=10)\n",
    "model4.summary()\n",
    "#val_accuracy = %99.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25054058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 0.9925\n",
      "Accuracy: 99.25\n"
     ]
    }
   ],
   "source": [
    "#final evalution of model4\n",
    "_, accuracy = model4.evaluate(xtest_c,ytest_oh)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
